{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c25f3ead",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import tabula\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04522994",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcee9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "def remover_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2dca0b",
   "metadata": {},
   "source": [
    "# Relatório"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700269d8",
   "metadata": {},
   "source": [
    "## Convert PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd817f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL\n",
    "url = 'http://www.mpsp.mp.br/portal/page/portal/Promotorias_de_Justica/regioes_adm/com_relacao_comarcas_municipios/Rela%C3%A7%C3%A3o%20munic%C3%ADpios%2013-01-2021%20%20(1).pdf'\n",
    "\n",
    "# File\n",
    "file = os.path.join('docs', 'Relação municípios 13-01-2021  (1).pdf')\n",
    "\n",
    "# Request\n",
    "r = requests.get(url)\n",
    "with open(file, 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7029ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PDF into CSV\n",
    "tabula.convert_into(\n",
    "    file,\n",
    "    os.path.join('data', 'tabs', 'tabula.csv'),\n",
    "    output_format='csv',\n",
    "    pages='all',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File\n",
    "file_in = os.path.join('data', 'tabs', 'tabula.csv')\n",
    "file_out = os.path.join('data', 'tabs', 'tabula_out.csv')\n",
    "\n",
    "# Open Files\n",
    "f_in = open(file_in, 'r')\n",
    "f_out = open(file_out,'w')\n",
    "for line in f_in:\n",
    "\tf_out.write(line.replace(',,', ','))\n",
    "\n",
    "f_in.close()\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333cfc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "df = pd.read_csv(\n",
    "    os.path.join('data', 'tabs', 'tabula_out.csv'),\n",
    "    usecols=['Localidade', 'Promotoria de Justiça Pertencente', 'Area Regional']\n",
    ")\n",
    "\n",
    "# Remove Acentos\n",
    "df['loc_id'] = df['Localidade'].apply(lambda x: x.replace('MOJI MIRIM', 'Mogi Mirim'))\n",
    "\n",
    "# Set Lower\n",
    "df['loc_id'] = df['loc_id'].str.lower()\n",
    "\n",
    "# Remove Acentos\n",
    "df['loc_id'] = df['loc_id'].apply(lambda x: remover_acentos(x))\n",
    "\n",
    "\n",
    "\n",
    "# Remove Acentos\n",
    "df['pj_id'] = df['Promotoria de Justiça Pertencente'].apply(lambda x: str(x).replace('MOJI MIRIM', 'Mogi Mirim'))\n",
    "\n",
    "# Set Lower\n",
    "df['pj_id'] = df['pj_id'].str.lower()\n",
    "\n",
    "# Remove Acentos\n",
    "df['pj_id'] = df['pj_id'].apply(lambda x: remover_acentos(x))\n",
    "\n",
    "\n",
    "\n",
    "# Remove Acentos\n",
    "df['ar_id'] = df['Area Regional'].apply(lambda x: str(x).replace('MOJI MIRIM', 'Mogi Mirim'))\n",
    "\n",
    "# Set Lower\n",
    "df['ar_id'] = df['ar_id'].str.lower()\n",
    "\n",
    "# Remove Acentos\n",
    "df['ar_id'] = df['ar_id'].apply(lambda x: remover_acentos(x))\n",
    "\n",
    "# Deleta Linhas e Colunas\n",
    "df.drop(\n",
    "    ['Localidade', 'Promotoria de Justiça Pertencente', 'Area Regional'],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    "    errors='ignore'\n",
    ")\n",
    "df = df.loc[df['loc_id'] != '41.262.199']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116af0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove\n",
    "os.remove(file_in)\n",
    "os.remove(file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e795d132",
   "metadata": {},
   "source": [
    "## Municípios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ba7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o arquivo csv com o nome dos municípios\n",
    "df_mun = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/michelmetran/sp/main/data/tabs/tab_municipios.csv',\n",
    "    usecols=['id_municipio', 'municipio_nome']\n",
    ")\n",
    "\n",
    "# Set Lower\n",
    "df_mun['nome_id'] = df_mun['municipio_nome'].str.lower()\n",
    "\n",
    "# Remove Acentos\n",
    "df_mun['nome_id'] = df_mun['nome_id'].apply(lambda x: remover_acentos(x))\n",
    "\n",
    "# Renomeia colunas\n",
    "df_mun.rename(columns={'municipio_nome': 'NOME'}, inplace=True, errors='ignore')\n",
    "\n",
    "df_mun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87406c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Municípios\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    df_mun,    \n",
    "    how='right',\n",
    "    left_on='loc_id',\n",
    "    right_on='nome_id',    \n",
    ")\n",
    "\n",
    "# Adjusts\n",
    "df['loc_id'] = df['NOME']\n",
    "df['id_loc'] = df['id_municipio']\n",
    "df.drop(['id_municipio', 'NOME', 'nome_id'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Renomeia colunas\n",
    "df.rename(\n",
    "    columns={\n",
    "        'loc_id': 'municipio_nome',\n",
    "        'id_loc': 'id_municipio',\n",
    "    },\n",
    "    inplace=True,\n",
    "    errors='ignore',\n",
    ")\n",
    "\n",
    "# \n",
    "df = df[[\n",
    "    'id_municipio',\n",
    "    'municipio_nome',\n",
    "    'pj_id',\n",
    "    'ar_id',    \n",
    "]].copy()\n",
    "\n",
    "# Results\n",
    "df.to_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_municipio.csv'),\n",
    "    index=False,\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f750dbf",
   "metadata": {},
   "source": [
    "## Área Regional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AREA REGIONAL\n",
    "df = pd.read_csv(os.path.join('data', 'tabs', 'tab_municipio.csv'))\n",
    "df_ar = df[['id_municipio', 'municipio_nome', 'ar_id']].copy()\n",
    "\n",
    "# Merge\n",
    "df = pd.merge(\n",
    "    df_ar,\n",
    "    df_mun,    \n",
    "    how='left',\n",
    "    left_on='ar_id',\n",
    "    right_on='nome_id',    \n",
    ")\n",
    "\n",
    "# Missing Values\n",
    "dict_ar = {\n",
    "    'capital': 1,\n",
    "    'grande sao paulo': 2,\n",
    "    'vale do ribeira': 3,\n",
    "}\n",
    "df_missing = pd.DataFrame(\n",
    "    list(dict_ar.items()),\n",
    "    columns=['ar_id','id_ar']\n",
    ")\n",
    "\n",
    "# Merge\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    df_missing,    \n",
    "    how='left',\n",
    "    left_on='ar_id',\n",
    "    right_on='ar_id',    \n",
    ")\n",
    "df['id_municipio_y'] = df['id_municipio_y'].fillna(0)\n",
    "df['id_ar'] = df['id_ar'].fillna(0)\n",
    "df['id_ar'] = df['id_ar'] + df['id_municipio_y']\n",
    "df['id_ar'] = df['id_ar'].astype(int)\n",
    "\n",
    "\n",
    "# Renomeia colunas\n",
    "df.rename(\n",
    "    columns={\n",
    "        'id_municipio_x': 'id_municipio',        \n",
    "        'NOME': 'ar_nome',\n",
    "    },\n",
    "    inplace=True,\n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "# Deleta\n",
    "df.drop(\n",
    "    [\n",
    "        'ar_id',\n",
    "        'nome_id',\n",
    "        'id_municipio_y',\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "# Missing Values\n",
    "dict_ar = {\n",
    "    1: 'Capital',\n",
    "    2: 'Grande São Paulo',\n",
    "    3: 'Vale do Ribeira',\n",
    "}\n",
    "df_missing = pd.DataFrame(\n",
    "    list(dict_ar.items()),\n",
    "    columns=['id_ar', 'NOME']\n",
    ")\n",
    "# Merge\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    df_missing,    \n",
    "    how='left',\n",
    "    left_on='id_ar',\n",
    "    right_on='id_ar',    \n",
    ")\n",
    "df['ar_nome'] = df['ar_nome'].fillna('') + df['NOME'].fillna('')\n",
    "df.drop(['NOME'], axis=1, inplace=True, errors='ignore')\n",
    "df = df[['id_municipio', 'municipio_nome', 'id_ar', 'ar_nome']].copy()\n",
    "\n",
    "# Results\n",
    "df.to_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_municipio_ar.csv'),\n",
    "    index=False,\n",
    ")\n",
    "display(df[44:48])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168ca330",
   "metadata": {},
   "source": [
    "## Área Regional: Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af292f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group\n",
    "df = pd.DataFrame(df.groupby(['id_ar', 'ar_nome'], dropna=False)['id_municipio'].count())\n",
    "df = df.reset_index()\n",
    "df.drop(df.columns[len(df.columns)-1], axis=1, inplace=True)\n",
    "\n",
    "# Results\n",
    "df.to_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_ar.csv'),\n",
    "    index=False,\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef57a6be",
   "metadata": {},
   "source": [
    "## Promotorias de Justiça"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21766c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_nome(x):\n",
    "    dict_rename = {\n",
    "        'embu guacu': 'embu-guacu',\n",
    "        'estrela doeste': \"estrela d'oeste\",\n",
    "        'palmeira doeste': \"palmeira d'oeste\",\n",
    "        'sao luiz do paraitinga': 'sao luis do paraitinga',\n",
    "        'santa rosa do viterbo': 'santa rosa de viterbo',\n",
    "    }\n",
    "    for k, v in dict_rename.items():\n",
    "        x = x.replace(k, v)    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9516c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRMOTORIAS DE JUSTIÇA\n",
    "df = pd.read_csv(os.path.join('data', 'tabs', 'tab_municipio.csv'))\n",
    "df_pj = df[['id_municipio', 'municipio_nome', 'pj_id']].copy()\n",
    "\n",
    "df_pj.loc[:, 'pj_id'] = df_pj['pj_id'].astype(str).apply(lambda x: rename_nome(x))\n",
    "\n",
    "# Merge\n",
    "df = pd.merge(\n",
    "    df_pj,\n",
    "    df_mun,    \n",
    "    how='left',\n",
    "    left_on='pj_id',\n",
    "    right_on='nome_id',    \n",
    ")\n",
    "\n",
    "#Renomeia colunas\n",
    "df.rename(\n",
    "    columns={\n",
    "        'id_municipio_x': 'id_municipio',\n",
    "        'id_municipio_y': 'id_pj',\n",
    "        'NOME': 'pj_nome',\n",
    "    },\n",
    "    inplace=True,\n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "# Deleta\n",
    "df.drop(\n",
    "    ['pj_id', 'nome_id'],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "# Results\n",
    "df.to_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_municipio_pj.csv'),\n",
    "    index=False,\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df69e98d",
   "metadata": {},
   "source": [
    "## Promotorias de Justiça: Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab8358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group\n",
    "df = pd.DataFrame(df.groupby(['id_pj', 'pj_nome'], dropna=False)['id_municipio'].count())\n",
    "df = df.reset_index()\n",
    "df.drop(df.columns[len(df.columns)-1], axis=1, inplace=True)\n",
    "\n",
    "# Results\n",
    "df.to_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_pj.csv'),\n",
    "    index=False,\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc109d8c",
   "metadata": {},
   "source": [
    "# Áreas Regionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07322a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BS4\n",
    "url = 'http://www.mpsp.mp.br/portal/page/portal/Promotorias_de_Justica'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "soup = soup.find('map', {'name': 'image-mapa'})\n",
    "\n",
    "# Create Empty Lists\n",
    "list_ar = []\n",
    "list_href = []\n",
    "\n",
    "# Fill Lists\n",
    "for i in list(soup.children):\n",
    "    try:\n",
    "        #print(i['title'])\n",
    "        #print(i['href'])\n",
    "        list_ar.append(str(i['title']))\n",
    "        list_href.append(str(i['href']))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Assign data to tuples.\n",
    "list_df = list(zip(list_ar, list_href))\n",
    "\n",
    "# Converting lists of tuples into\n",
    "df = pd.DataFrame(list_df, columns = ['ar_nome', 'url'])\n",
    "\n",
    "# Adjust URLs\n",
    "prefix = 'http://www.mpsp.mp.br'\n",
    "df['url'] = df['url'].apply(lambda x: x.replace(prefix, ''))\n",
    "df['url'] = prefix + df['url']\n",
    "\n",
    "# Results\n",
    "df.to_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_ar_url.csv'),\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa6744",
   "metadata": {},
   "source": [
    "# Promotorias de Justiça\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/1MuzCoK1uAf_gVqJ6Coi4a1KAEtnYT4Kzu6mTAhZlE_s/edit#gid=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0df50a",
   "metadata": {},
   "source": [
    "## Municípios com PJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bbc492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mun_pj(url, ar):\n",
    "    # BS4\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    soup = soup.find('map', {'name': 'FPMap0'})\n",
    "\n",
    "    # Create Empty Lists\n",
    "    list_ar = []\n",
    "    list_href = []\n",
    "\n",
    "    # Fill Lists\n",
    "    for i in list(soup.children):\n",
    "        try:\n",
    "            #print(i['alt'])\n",
    "            #print(i['href'])\n",
    "            list_ar.append(str(i['alt']))\n",
    "            list_href.append(str(i['href']))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Assign data to tuples.\n",
    "    list_df = list(zip(list_ar, list_href))\n",
    "\n",
    "    # Converting lists of tuples into\n",
    "    df = pd.DataFrame(list_df, columns = ['pj', 'url'])\n",
    "\n",
    "    # Adjust URLs\n",
    "    prefix = 'http://www.mpsp.mp.br'\n",
    "    df['url'] = df['url'].apply(lambda x: x.replace(prefix, ''))\n",
    "    df['url'] = prefix + df['url']\n",
    "\n",
    "    # Remove Broken Lines\n",
    "    df['pj'] = df['pj'].apply(lambda x: x.replace('\\r\\n',''))\n",
    "    df['url'] = df['url'].apply(lambda x: x.replace('\\r\\n',''))\n",
    "    \n",
    "    # Add Column\n",
    "    df['municipio'] = df['pj']\n",
    "    df['ar'] = ar\n",
    "    df['tem_pj'] = 'Sim'\n",
    "\n",
    "    # Drop Duplicates and Sort\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.sort_values(by=['municipio'], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac0b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read AR dataframe\n",
    "df = pd.read_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_ar_url.csv'),\n",
    ")\n",
    "\n",
    "# Create Empty dataframe\n",
    "df_pj_final = pd.DataFrame()\n",
    "\n",
    "# Loop to append data\n",
    "for k, v in df.iterrows():\n",
    "    url = v['url']\n",
    "    ar = v['ar_nome']\n",
    "    print(ar)\n",
    "    try:\n",
    "        df_pj = get_mun_pj(url, ar)\n",
    "        df_pj_final = df_pj_final.append(df_pj)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Results\n",
    "df_pj_final.to_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_pjs_mun.csv'),\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567f3d1c",
   "metadata": {},
   "source": [
    "## Municípios sem PJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb78129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mun_small(url, ar):\n",
    "    # BS4\n",
    "    #url = 'http://www.mpsp.mp.br/portal/page/portal/Promotorias_de_Justica/regioes_adm/relacoes_regionais/rel_regionais_bauru/mapa_bauru'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    soup = soup.find('div', {'class': 'cabecalho_regiao'})\n",
    "    soup\n",
    "\n",
    "    # Sobe dois tables\n",
    "    soup = soup.find_parent('table')\n",
    "    soup = soup.find_parent('table')\n",
    "\n",
    "    # Vai pro proximo table\n",
    "    soup = soup.find_next('table')\n",
    "    soup = soup.find_next('table')\n",
    "\n",
    "    # Table inside table\n",
    "    soup = soup.find('table')\n",
    "\n",
    "    data = []\n",
    "    rows = soup.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        url = row.find('a').get('href')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        cols.append(url)\n",
    "        data.append([ele for ele in cols if ele])\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        data,\n",
    "        columns=['municipio', 'pj', 'url']\n",
    "    )\n",
    "\n",
    "    # Adjust URLs\n",
    "    prefix = 'http://www.mpsp.mp.br'\n",
    "    df['url'] = df['url'].apply(lambda x: x.replace(prefix, ''))\n",
    "    df['url'] = prefix + df['url']\n",
    "\n",
    "    # Remove Broken Lines\n",
    "    df['municipio'] = df['municipio'].apply(lambda x: x.replace('\\r\\n',''))\n",
    "    df['pj'] = df['pj'].apply(lambda x: x.replace('\\r\\n',''))\n",
    "    df['url'] = df['url'].apply(lambda x: x.replace('\\r\\n',''))\n",
    "\n",
    "    # Adjust\n",
    "    df['pj'] = df['pj'].apply(lambda x: x.replace('Promotoria de Justiça de ',''))\n",
    "    df['ar'] = ar\n",
    "    df['tem_pj'] = 'Não'\n",
    "\n",
    "    # Drop Duplicates and Sort\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.sort_values(by=['municipio'], ignore_index=True)\n",
    "\n",
    "    # Results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00fa44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read AR dataframe\n",
    "df = pd.read_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_ar_url.csv'),\n",
    ")\n",
    "\n",
    "# Create Empty dataframe\n",
    "df_pj_final = pd.DataFrame()\n",
    "\n",
    "# Loop to append data\n",
    "for k, v in df.iterrows():\n",
    "    url = v['url']\n",
    "    ar = v['ar_nome']\n",
    "    print(ar)\n",
    "    try:\n",
    "        df_pj = get_mun_small(url, ar)\n",
    "        df_pj_final = df_pj_final.append(df_pj)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Results\n",
    "df_pj_final.to_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_pjs_smallmun.csv'),\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbcbfef",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "file = os.path.join('data', 'tabs', 'tab_mun_small.csv')\n",
    "df_mun_small = pd.read_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_mun_small.csv'),\n",
    ")\n",
    "#os.remove(file)\n",
    "\n",
    "# Results\n",
    "file = os.path.join('data', 'tabs', 'tab_mun_pjs.csv')\n",
    "df_mun_pjs = pd.read_csv(\n",
    "    file,\n",
    ")\n",
    "#os.remove(file)\n",
    "\n",
    "# Append\n",
    "df_mun_small = df_mun_small.append(df_mun_pjs)\n",
    "df = df_mun_small\n",
    "\n",
    "# Adjust\n",
    "df = df.sort_values(by=['municipio', 'tem_pj'], ignore_index=True)\n",
    "df.drop_duplicates(subset='municipio', keep='first', inplace=True)\n",
    "\n",
    "# Results\n",
    "df.to_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_pjs.csv'),\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f11eb",
   "metadata": {},
   "source": [
    "## Join Municípios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce82fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o arquivo csv com o nome dos municípios\n",
    "df_mun = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/michelmetran/sp/main/data/tabs/tab_municipios.csv',\n",
    "    usecols=['id_municipio', 'municipio_nome']\n",
    ")\n",
    "\n",
    "# Set Lower\n",
    "df_mun['municipio_nome_lower'] = df_mun['municipio_nome'].str.lower()\n",
    "\n",
    "# Remove Acentos\n",
    "df_mun['municipio_nome_lower'] = df_mun['municipio_nome_lower'].apply(lambda x: remover_acentos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "df = pd.read_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_pjs.csv'),\n",
    ")\n",
    "\n",
    "# Set Lower\n",
    "df['municipio_nome_lower'] = df['municipio'].str.lower()\n",
    "\n",
    "# Remove Acentos\n",
    "df['municipio_nome_lower'] = df['municipio_nome_lower'].apply(lambda x: remover_acentos(x))\n",
    "\n",
    "# Merge\n",
    "df = pd.merge(\n",
    "    df_mun,\n",
    "    df,\n",
    "    how='left',\n",
    "    left_on='municipio_nome_lower',\n",
    "    right_on='municipio_nome_lower'\n",
    ")\n",
    "\n",
    "# Results\n",
    "df.to_csv(\n",
    "    os.path.join('data', 'tabs', 'tab_pjs_merge.csv'),\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79047a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3c078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c16c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "069810fe",
   "metadata": {},
   "source": [
    "# GAEMAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3396dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for row in soup.find_all('tr'):\n",
    "    print(row.text)\n",
    "    #print(row.find('td'))\n",
    "    try:\n",
    "        #print(row.get_atrribute('href'))\n",
    "        pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d0ee32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24596922",
   "metadata": {},
   "source": [
    "# Macroregiões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'http://www.mpsp.mp.br/portal/page/portal/noticias/noticia?id_noticia=19968257&id_grupo=118'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee6c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pablocarreira-py38] *",
   "language": "python",
   "name": "conda-env-pablocarreira-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
